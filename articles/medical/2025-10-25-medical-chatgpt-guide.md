# 医療現場でのChatGPT活用完全ガイド - 医師・看護師・薬剤師のための実践マニュアル

日付: 2025-10-25
カテゴリ: medical
タグ: ChatGPT, 医療AI, 厚生労働省ガイドライン, 医師, 看護師, 薬剤師

---

## はじめに - 医療現場でChatGPTは本当に使えるのか？禁止されているのか？

あなたは医療現場でChatGPTを使ってみたいと思ったことはありませんか。診断書の作成、文献検索、患者説明資料の準備など、日々の業務で時間がかかる作業を効率化できれば、患者さんとのコミュニケーションにより多くの時間を使えるでしょう。

しかし、「医療現場でChatGPTは禁止されているのではないか」という疑問を持つ方も多いはずです。結論から申し上げますと、ChatGPTは医療現場で完全に禁止されているわけではありません。ただし、2023年5月に策定された厚生労働省のガイドライン第6.0版（Q&Aは2025年5月に更新）により、電子カルテ情報などの医療情報を扱う際には厳格なルールが設けられています。

具体的には、電子カルテの医療情報は原則として国内サーバーに保存する必要があり、ChatGPTやClaudeのように30日間ログを保存するサービスでは、この要件を満たせません。つまり、「学習目的で保存されない」設定にするだけでは不十分なです。

しかし、これは電子カルテ情報に限った話です。患者情報を完全に匿名化した上での活用、文献検索、勉強会資料の作成など、個人情報を含まない用途であれば、ChatGPTは有効に活用できます。実際に、診断書作成の時間が従来の10分の1になった医療機関や、文献検索の効率が大幅に向上した事例も報告されています。

この記事では、医療現場でのChatGPT活用法について、厚生労働省のガイドラインから実践的なプロンプト例、リスク管理まで網羅的に解説します。医師、看護師、薬剤師、医療事務など、すべての医療従事者が安全にChatGPTを活用するための知識を提供します。

## 第1章: 医療現場におけるChatGPT - 基礎知識と最新動向

### 1.1 ChatGPTとは何か - 医療従事者が知っておくべき仕組み

ChatGPTは、OpenAI社が開発した大規模言語モデル（LLM）を用いた対話型AIです。インターネット上の膨大なテキストデータを学習し、人間のような自然な文章を生成できます。

医療従事者が理解しておくべき重要な点は、ChatGPTは「データベース」ではなく「文章生成AI」だということです。つまり、正確な情報を検索して表示しているのではなく、学習したパターンから「それらしい文章」を作り出しているです。この特性を理解していないと、誤った情報を鵜呑みにしてしまう危険があります。

基本的な仕組みとしては、ユーザーが入力した質問や指示（プロンプト）に対して、学習したパターンをもとに最も適切と思われる回答を生成します。医療文献の要約、診断書の下書き作成、患者向け説明資料の準備など、幅広い用途に活用できます。

ただし、ChatGPTの学習データには期限があり、無料版では2021年9月までの情報しか持っていません。2021年9月以降に承認された新薬や、最新のガイドライン改定には対応していないため、最新の医療情報については必ず公式の情報源で確認する必要があります。

### 1.2 2025年版：医療AIの進化と現状

2025年8月7日より、ChatGPTのモデルは「GPT-5」に統一されました。これまではGPT-3.5、GPT-4、GPT-4oなど複数のモデルが存在していましたが、現在はAIがタスクに応じて最適なモデルを自動的に選択する仕組みになっています。

この統一により、医療従事者は「どのモデルを使うべきか」を悩む必要がなくなりました。複雑な医療文献の分析であれば精度の高いモデルが、簡単な文章作成であれば高速なモデルが自動的に選ばれます。

また、ChatGPTの診断能力についても研究が進んでいます。海外の大学の研究では、ChatGPTが救急患者を医師と同程度の正確性で診断できることが示されました。ただし、これはあくまで研究段階の結果であり、実際の臨床現場での使用には慎重な検討が必要です。

医療AI全般についても、画像診断支援、薬剤相互作用チェック、電子カルテの自動要約など、様々な分野で実用化が進んでいます。ChatGPTはその中でも汎用性の高いツールとして、文書作成や情報整理の分野で活用が期待されています。

### 1.3 医療現場での導入状況

現在、ChatGPTを医療現場で活用している医療機関は徐々に増えています。特に若い世代の医師や、業務効率化に関心の高い医療従事者の間で活用が広がっています。

具体的な導入事例としては、診断書や紹介状の下書き作成に活用し、作成時間を従来の10分の1に短縮した医療機関があります。また、文献検索や論文の要約にChatGPTを使い、最新の医療知識のキャッチアップ時間を大幅に削減した医師もいます。

ただし、厚生労働省のガイドライン改定により、電子カルテ情報の取り扱いには厳格なルールが設けられたため、多くの医療機関では慎重な姿勢を取っています。金融機関や病院などでは、AI使用を完全に禁止したり、入出力データの事前チェックを義務付けたりする内部ルールを設けているケースもあります。

一方で、個人情報を含まない用途（文献検索、勉強会資料作成、一般的な医療知識の整理など）では、積極的に活用する医療従事者が増えています。医師向けの臨床支援アプリ「HOKUTO」にもGPT-4を活用した新機能が導入されるなど、医療向けのAIツールも充実してきています。

### 1.4 ChatGPTが得意なこと・不得意なこと

医療現場でChatGPTを効果的に使うためには、何が得意で何が苦手なのかを理解しておく必要があります。

得意なことは、文章の要約、翻訳、言い換え、アイデア出しです。英語の医学論文を日本語で要約したり、診断書の下書きを作成したり、患者向けの説明文を平易な言葉に言い換えたりする作業では高いパフォーマンスを発揮します。また、勉強会資料の構成案を作成したり、疑義照会の文章の叩き台を作ったりすることも得意です。

一方で、苦手なことは正確性が求められる専門知識の提供です。特に医療情報では、投与量や禁忌事項などを誤って回答することがあります。これを「ハルシネーション」と呼びますが、AIが自信を持って間違った情報を提示するため、知識のない人は見抜けません。

また、最新の情報にも弱点があります。無料版では2021年9月までの情報しか持っていないため、それ以降に承認された新薬や、ガイドラインの改定には対応できません。有料版でもWeb検索機能を使わない限り、最新の医療情報には対応できないです。

診断についても、研究では一定の精度が示されていますが、身体診察ができない、検査結果の解釈に限界がある、個別の患者背景を考慮できないなどの制約があります。ChatGPTはあくまで「診断支援」のツールであり、最終的な診断は必ず医師が行う必要があります。

医療従事者がChatGPTを使う際は、「下書き作成や情報整理には使えるが、最終的な内容の正確性は必ず自分で確認する」という姿勢が必須です。

## 第2章: 厚生労働省ガイドラインと法規制 - ChatGPTは禁止されているのか？

### 2.1 ガイドライン第6.0版とQ&A更新の詳細

厚生労働省は2023年5月に「医療情報システムの安全管理に関するガイドライン第6.0版」を策定し、その後2025年5月にQ&Aを更新しました。このQ&A更新では、医療現場での生成AI使用に関する解釈が追加され、医療現場に大きな影響を与えています。

更新の要点は、電子カルテの医療情報は原則として国内サーバーに保存する必要があり、生成AIを医療情報の入力に使用できるのは「学習目的で保存されない」場合に限られるというもです。つまり、完全に禁止されているわけではなく、厳格な条件を満たせば使用可能なです。

ただし、この「学習目的で保存されない」という要件が問題です。ChatGPTやClaudeは、設定で「チャット履歴と学習」をオフにしても、30日間はログを保存します。このため、ガイドラインのQ&Aが求める「医療情報が保存されない」という要件を満たせません。

この改定により、多くの医療機関では電子カルテ情報をChatGPTに入力することを控えるようになりました。ただし、完全に匿名化された情報や、個人情報を含まない医療知識の整理などには、引き続き活用できます。

### 2.2 電子カルテ情報の取り扱いルール

電子カルテ情報をChatGPTで扱う際の具体的なルールを整理します。

まず、原則として電子カルテの医療情報は国内サーバーに保存する必要があります。ChatGPTのサーバーは海外にあるため、この要件を満たせません。また、医療情報は「保存されない」ことが条件ですが、ChatGPTは30日間ログを保存するため、この条件も満たせないです。

ただし、以下のような対応をすれば、ChatGPTを活用できる余地があります。

まず、患者情報を完全に匿名化することです。氏名、生年月日、住所、電話番号など、個人を特定できる情報をすべて削除し、「60代男性、糖尿病で治療中」といった一般的な表現に置き換えれば、個人情報保護の観点からは問題ありません。

次に、電子カルテ情報そのものではなく、一般的な医療知識の整理や、文献情報の要約などに用途を限定することです。「糖尿病の治療ガイドラインを要約してください」といった質問であれば、電子カルテ情報を扱っているわけではないため、ガイドラインの制約は受けません。

また、診断書や紹介状の下書きを作成する際も、テンプレートや一般的な文例を作成する用途であれば問題ありません。実際の患者情報を入力するのではなく、「高血圧患者への診断書のテンプレートを作成してください」といった形で活用します。

### 2.3 ChatGPT・Claudeのログ保存問題

ChatGPTとClaudeのログ保存問題について、詳しく見ていきましょう。

ChatGPTの設定には「チャット履歴と学習」という項目があり、これをオフにすれば学習に使われないと説明されています。しかし、OpenAI社の規約によれば、この設定をオフにしても30日間はログが保存されます。これは、不正利用の監視やサービス改善のために保存されるもです。

Claudeも同様に、設定を変更しても一定期間はログを保存します。このため、厚生労働省のガイドラインが求める「医療情報が保存されない」という要件を、これらのサービスは満たせないです。

この問題に対する医療機関の対応は分かれています。ある医療機関では、電子カルテ情報のChatGPT使用を完全に禁止し、違反者には懲戒処分を科すという厳しいルールを設けています。一方で、完全匿名化を徹底した上で、限定的に使用を認めている医療機関もあります。

将来的には、医療機関向けに、ログを一切保存しない専用のChatGPTサービスが提供される可能性もあります。OpenAI社は企業向けのEnterpriseプランを提供しており、このプランではデータ保持期間を短縮できるオプションがあります。医療機関向けに特化したプランが登場すれば、状況は変わる可能性があります。

### 2.4 医療機関での使用可否の判断基準

医療機関でChatGPTを使用して良いかどうか、判断基準を整理します。

使用してはいけないケースは、電子カルテの患者情報をそのまま入力する場合です。氏名、生年月日、住所、カルテ番号などの個人情報を含む情報は、絶対に入力してはいけません。これは厚生労働省のガイドラインに違反するだけでなく、個人情報保護法違反にもなります。

また、未確認の診断や治療方針を、ChatGPTの回答だけで決定することも避けるべきです。ChatGPTはハルシネーションを起こす可能性があるため、最終的な判断は必ず医師が行う必要があります。

一方で、使用しても問題ないケースは、完全に匿名化された情報を扱う場合です。「60代男性、2型糖尿病、HbA1c 8.5%」といった形で個人を特定できない情報であれば、ChatGPTに入力しても個人情報保護の観点からは問題ありません。

また、一般的な医療知識の整理、文献検索、勉強会資料の作成など、個人情報を含まない用途であれば、自由に活用できます。「糖尿病の最新治療について要約してください」「心不全の勉強会資料の構成案を作成してください」といった質問は、何の問題もありません。

診断書や紹介状の下書き作成も、テンプレートや文例を作成する用途であれば活用できます。実際の患者情報を入力するのではなく、一般的な文章構成を作成し、その後で実際の患者情報を医療従事者が追記するという使い方です。

### 2.5 違反した場合のリスクと罰則

厚生労働省のガイドラインに違反した場合、どのようなリスクがあるのでしょうか。

まず、個人情報保護法違反に問われる可能性があります。患者の個人情報をChatGPTに入力し、それが第三者に漏洩した場合、医療機関は個人情報保護委員会から指導や命令を受ける可能性があります。悪質な場合は、懲役または罰金が科されることもあります。

また、医療機関としての信頼を失うリスクもあります。患者情報の漏洩が報道されれば、患者から信頼を失い、経営に大きな影響を与えます。特に、SNSで拡散されれば、風評被害は計り知れません。

医療従事者個人に対しても、懲戒処分のリスクがあります。多くの医療機関では、AI使用に関する内部ルールを設けており、これに違反した場合は懲戒処分の対象になります。最悪の場合、解雇されることもあります。

さらに、ChatGPTの誤情報に基づいて医療行為を行い、患者に健康被害が生じた場合、医療過誤として訴えられる可能性もあります。「ChatGPTがそう言ったから」という言い訳は通用しません。最終的な判断と責任は、医療従事者が負うです。

これらのリスクを避けるためには、厚生労働省のガイドラインを遵守し、個人情報は絶対に入力しない、ChatGPTの回答は必ず確認する、という基本原則を徹底することが必要です。また、医療機関全体で明確なルールを作り、全スタッフに周知することも必要です。

## 第3章: 医療従事者別ChatGPT活用シーン

### 3.1 医師の活用法：診断書、紹介状、カルテ記載の効率化

医師がChatGPTを活用できる場面は多岐にわたります。最も効果が大きいのは、診断書や紹介状の下書き作成です。

診断書の作成は時間がかかる作業ですが、ChatGPTにテンプレートを作成させれば、大幅に時間を短縮できます。「高血圧症の診断書のテンプレートを作成してください」と依頼すれば、一般的な診断書の構成を提示してくれます。その後、実際の患者情報や検査結果を医師が追記すれば完成です。

ある医療機関では、紹介状の作成にChatGPTを活用し、従来20〜30分かかっていた作業を3〜5分で完成させるようになりました。患者の背景（年齢、性別、主訴）を匿名化してChatGPTに入力し、紹介状の下書きを作成させます。医師は内容を確認・修正するだけで済むため、大幅な時間短縮が実現しました。

カルテ記載の効率化にも活用できます。SOAP形式のカルテ記載について、主観的情報（S）、客観的情報（O）を簡単にメモしておき、「以下の内容をSOAP形式で整理してください」と依頼すれば、評価（A）と計画（P）の叩き台も含めて作成してくれます。ただし、患者の個人情報は必ず削除してから入力してください。

また、文献調査も医師の重要な業務です。英語の医学論文を読む際、まずChatGPTでアブストラクトを日本語に要約してもらい、興味深い内容であれば原文を精読するという流れが効率的です。すべての論文を精読するのは時間的に困難ですが、ChatGPTを使えば多くの論文を短時間でスクリーニングできます。

### 3.2 看護師の活用法：看護記録、患者説明資料

看護師もChatGPTを効果的に活用できます。特に看護記録の作成と、患者向け説明資料の準備で威力を発揮します。

看護記録の作成は、看護師の日常業務で最も時間がかかる作業の一つです。患者さんとの会話内容や観察事項を簡単にメモしておき、「以下の内容を看護記録として整理してください」と依頼すれば、適切な形式で記録を作成してくれます。ただし、患者情報は必ず匿名化し、「70代女性、術後3日目、歩行訓練実施」といった形で入力してください。

患者向けの説明資料作成にも有効です。手術前の説明、退院指導、自宅でのケア方法など、患者さんに説明する内容をわかりやすい言葉で作成する必要があります。ChatGPTに「心臓カテーテル検査について、高齢者にもわかりやすく説明する資料を作成してください」と依頼すれば、専門用語を避けた平易な説明文を生成してくれます。

また、看護計画の立案にも活用できます。「心不全患者の看護計画の例を提示してください」と質問すれば、一般的な看護計画の構成を示してくれます。これを参考に、実際の患者さんに合わせた個別の看護計画を作成すれば、計画立案の時間を短縮できます。

勉強会の資料作成も看護師の業務です。「糖尿病患者の足病変予防について、看護師向けの勉強会資料の構成案を作成してください」と依頼すれば、目次や各セクションの要点を提示してくれます。

### 3.3 薬剤師の活用法：服薬指導、薬歴作成

薬剤師のChatGPT活用法については、前の記事で詳しく解説しましたが、ここでも要点をまとめます。

服薬指導の説明文作成にChatGPTは有効です。「糖尿病患者にインスリン注射の使い方を説明する文章を、高齢者にもわかりやすいように作成してください」と依頼すれば、平易な言葉で説明文を作ってくれます。医療従事者が当たり前に使っている言葉でも、患者さんには理解されていないことがあります。「服用」を「飲む」に、「空腹時」を「食事の前」に言い換えるだけで、患者さんの理解度は大きく向上します。

薬歴作成の効率化も可能です。患者さんとの会話内容を簡単にメモしておき、「以下の内容をSOAP形式の薬歴にまとめてください」と依頼すれば、S（主観的情報）、O（客観的情報）、A（評価）、P（計画）に整理してくれます。ただし、患者の個人情報は絶対に入力しないでください。

また、添付文書の要約にも便利です。長い添付文書を読む前に、「この添付文書の用法・用量、副作用、注意点を200字以内で要約してください」と依頼すれば、要点を素早く把握できます。ただし、ChatGPTの要約はあくまで参考情報として使い、実際の服薬指導の際には必ず添付文書の原文を確認してください。

### 3.4 医療事務の活用法：書類作成、スケジュール管理

医療事務スタッフもChatGPTを活用できます。特に書類作成とコミュニケーションの分野で効果があります。

診療報酬請求に関する書類作成では、レセプトコメントの文章作成に活用できます。「腰痛症で週2回のリハビリテーションを実施している理由を説明するコメントを作成してください」と依頼すれば、適切な文章を提示してくれます。ただし、患者の個人情報は含めないように注意してください。

また、患者さんへの案内文書の作成にも使えます。「インフルエンザ予防接種のお知らせ文を作成してください」と依頼すれば、接種時期、料金、注意事項などを含めた案内文を作成してくれます。その後、医療機関の具体的な情報を追記すれば完成です。

クレーム対応の文章作成にも活用できます。「待ち時間が長いとクレームを言っている患者への謝罪とフォローの文章を作成してください」と依頼すれば、適切な対応文を提示してくれます。ただし、実際の対応では、患者さんの状況に応じて柔軟にアレンジすることが必要です。

スケジュール調整の文章も、ChatGPTに作成させられます。「検査予約の変更をお願いするメールを作成してください」と依頼すれば、丁寧な文章を生成してくれます。

### 3.5 共通の活用法：文献検索、勉強会資料作成

すべての医療従事者に共通する活用法として、文献検索と勉強会資料の作成があります。

文献検索では、英語の医学論文の要約が特に有効です。論文のアブストラクトをコピーして、「この論文の要点を日本語で3つにまとめてください」と依頼すれば、数秒で要約を得られます。さらに「この論文の臨床的意義を説明してください」と追加で質問すれば、実務にどう活かせるかの示唆も得られます。

また、特定のトピックについて複数の情報源を調査したい場合は、GeminiのDeep Research機能が有効です。「SGLT2阻害薬の心不全への効果について、最新の研究動向をまとめてください」と依頼すると、複数の論文やニュース記事を調査し、要点をまとめたレポートを作成してくれます。

勉強会資料の作成では、まず構成案をChatGPTに作成させるのが効率的です。「新規抗凝固薬DOACについて、医療従事者向けの勉強会資料の構成案を作成してください」と依頼すれば、目次や各セクションの要点を提示してくれます。その構成案をもとに、各セクションの詳細をChatGPTに作成させ、自分で内容を確認・修正すれば、資料作成の時間を大幅に短縮できます。

ただし、医療情報の正確性は最優先です。ChatGPTが生成した内容は必ず最新のガイドラインや文献で確認してください。特に投与量や禁忌事項については、誤情報が含まれている可能性があるため、慎重にチェックが必要です。

## 第4章: 実践！医療従事者向けChatGPTプロンプト集

インターネット上には「医療従事者向けChatGPTプロンプト集」といった資料が公開されています。ここでは、その中から特に実用性の高いプロンプト例を厳選して紹介します。

### 4.1 診断書・紹介状作成のプロンプト例

診断書や紹介状の下書き作成に使えるプロンプト例です。

「高血圧症の診断書のテンプレートを作成してください。診断名、症状、治療内容、今後の見通しを含めてください。」

「整形外科から内科への紹介状のテンプレートを作成してください。糖尿病の管理をお願いする内容です。」

「労災診断書の基本的な構成を示してください。」

「診断書を患者さんにわかりやすく説明するための補足資料を作成してください。」

これらのプロンプトは、診断書や紹介状のテンプレートを作成する際に有効です。ただし、実際の患者情報を入力してはいけません。テンプレートを作成した後、医療従事者が実際の患者情報を追記する形で使用してください。

プロンプトのポイントは、「何について」「どのような構成で」「何を含めるか」を明確に指定することです。曖昧な質問では曖昧な回答しか得られません。

### 4.2 文献調査・論文要約のプロンプト例

論文や医療情報を調査する際に使えるプロンプト例です。

「以下の論文の要点を日本語で3つにまとめてください。」（論文のアブストラクトを貼り付ける）

「この論文の臨床的意義を、医療現場での活用という観点から説明してください。」

「この論文の研究デザイン、対象患者、主要評価項目、結果を箇条書きで整理してください。」

「糖尿病治療の最新ガイドラインについて、2021年版からの主な変更点をまとめてください。」

「心不全治療における最新のエビデンスを要約してください。」

論文の要約はChatGPTの得意分野ですが、専門用語の訳が不正確な場合があります。また、2021年9月以降の情報は無料版では取得できないため、最新情報が必要な場合は有料版のWeb検索機能を使うか、直接データベースを検索してください。

### 4.3 患者説明資料作成のプロンプト例

患者さん向けの説明資料を作成する際に使えるプロンプト例です。

「糖尿病患者にインスリン注射の使い方を説明する資料を、高齢者にもわかりやすいように作成してください。」

「心臓カテーテル検査について、検査前日から当日までの流れを患者さん向けに説明する資料を作成してください。」

「抗凝固薬を服用中の患者が出血したときの対処法を、患者さん向けにわかりやすく説明してください。」

「糖尿病の食事療法について、患者さん向けの説明資料を箇条書きで作成してください。」

「手術後の自宅でのケア方法について、患者さん向けの説明文を作成してください。」

これらのプロンプトで生成された説明文は、そのまま使うのではなく、内容を確認して自分の言葉に修正してから使うのが良いでしょう。特に投与方法や注意事項は、誤情報がないか慎重に確認してください。

### 4.4 医療統計・データ分析のプロンプト例

医療統計やデータ分析に使えるプロンプト例です。

「臨床試験で使用される統計手法について、t検定、カイ二乗検定、ロジスティック回帰分析の違いを説明してください。」

「サンプルサイズの計算方法について、わかりやすく説明してください。」

「p値と信頼区間の意味を、医療従事者向けに説明してください。」

「生存時間解析の基本的な考え方を説明してください。」

「この臨床データから適切な統計手法を提案してください。」（データの概要を入力）

ChatGPTのAdvanced Data Analysis機能を使えば、実際にデータをアップロードして解析することもできます。ただし、患者の個人情報を含むデータは絶対にアップロードしないでください。また、ChatGPTがあるからといって統計を学ばなくていいわけではありません。医療統計解析は、臨床経験と統計的知識を兼ね備えた人間にしかできない判断が必要です。

### 4.5 勉強会・研修資料作成のプロンプト例

院内勉強会や研修資料を作成する際に使えるプロンプト例です。

「新規抗凝固薬DOACについて、医療従事者向けの勉強会資料の構成案を作成してください。」

「心不全治療薬について、スライド5枚分の資料の構成を考えてください。各スライドのタイトルと含めるべき内容を提案してください。」

「ポリファーマシーの問題点と対策について、介護施設向けの研修資料を作成してください。」

「感染対策について、病棟スタッフ向けの勉強会資料の目次を作成してください。」

「医療安全について、新人看護師向けの研修資料の構成案を提案してください。」

勉強会資料の構成案をChatGPTに作成させると、全体の流れを素早く設計できます。その後、各セクションの詳細をChatGPTに作成させ、最新のガイドラインや文献で内容を確認・修正すれば、資料作成の時間を大幅に短縮できます。

### 4.6 プロンプトの書き方のコツ（医療特化）

医療現場で効果的なプロンプトを書くためのコツをまとめます。

まず、具体的に指示することです。「糖尿病について教えてください」という曖昧な質問では、一般論しか返ってきません。「2型糖尿病患者にSGLT2阻害薬を処方する際の注意点を、腎機能、脱水、尿路感染の観点から説明してください」と具体的に指示すれば、実用的な回答が得られます。

次に、出力形式を指定することです。「箇条書きで」「表形式で」「200字以内で」といった形式の指定により、求める形の回答が得やすくなります。忙しい医療現場では、簡潔にまとめられた情報の方が使いやすいでしょう。

役割を与えるのも有効です。「あなたは経験豊富な循環器内科医です。以下の症例について、鑑別診断を挙げてください」といった形で役割を設定すると、より専門的な視点での回答が得られます。

段階的に質問するのも良い方法です。いきなり複雑な質問をするのではなく、まず基本的な情報を確認し、その回答を踏まえて追加の質問をすると、より深い理解が得られます。

最後に、ChatGPTの回答を鵜呑みにせず、必ず確認することです。特に医療情報では、誤情報が含まれている可能性があるため、最終的な判断は必ず自分で行ってください。添付文書、ガイドライン、信頼できる医療情報源で確認する習慣をつけましょう。

## 第5章: 医療診断にChatGPTは使えるのか？ - 可能性と限界

### 5.1 診断精度の研究結果（救急患者診断で医師と同程度）

ChatGPTの診断能力について、いくつかの研究が発表されています。その中でも注目すべきは、オランダのイェルーン・ボッシュ病院のSteef Kurstjens氏らによる研究で、ChatGPTが救急患者を医師と同程度の正確性で診断できることが示されたもです。この研究結果は、欧州救急医学会（EUSEM 2023）で発表され、「Annals of Emergency Medicine」に2023年9月9日掲載されました。

この研究では、2022年3月に同病院の救急外来を受診した30人の患者について、2人の医師チームとChatGPT（無料版と有料版）が診療記録や検査値を評価しました。リストアップされた上位5つの疾患の中に実際の診断名が含まれていた確率は、医師チームで87％、無料版ChatGPTで97％、有料版ChatGPTで87％でした。特に一般的な疾患（感染症、消化器疾患、循環器疾患など）では、診断精度が高かったとされています。

ただし、この研究結果にはいくつかの重要な注意点があります。まず、研究の対象は比較的典型的な症例であり、複雑な症例や稀な疾患では精度が低下する可能性があります。また、身体診察所見や検査結果を総合的に判断する必要がある症例では、ChatGPTは十分な情報を得られません。

さらに、研究では患者の症状を研究者が整理してChatGPTに入力していますが、実際の診療現場では、患者から症状を聞き出す問診技術も診断の重要な要素です。ChatGPTは患者と直接対話できないため、この部分は医師が担う必要があります。

また、研究結果が出たからといって、すぐに臨床現場で使用できるわけではありません。日本では厚生労働省の規制があり、電子カルテ情報をChatGPTに入力することは推奨されていません。研究段階の成果を臨床に応用するには、慎重な検証と規制への対応が必要です。

### 5.2 ChatGPTが診断できること・できないこと

ChatGPTが診断に関してできることと、できないことを整理しましょう。

できることは、症状から鑑別診断のリストを作成することです。「40代男性、胸痛、冷や汗、息切れを訴えている」という情報を入力すれば、心筋梗塞、不安定狭心症、肺塞栓症、大動脈解離など、考えるべき鑑別診断を挙げてくれます。これは医学生や研修医の学習に役立ちます。

また、典型的な症状パターンから可能性の高い疾患を推測することもできます。「発熱、咳嗽、胸部痛」という症状があれば、肺炎を疑うべきという一般的な医学知識を提示できます。

一方で、できないことも多くあります。まず、身体診察ができません。聴診、触診、視診、打診といった身体診察は診断に不可欠ですが、ChatGPTは患者を実際に診察できないため、これらの情報は得られません。

また、検査結果の解釈にも限界があります。血液検査、画像検査の結果を総合的に判断するには、臨床経験が必要です。ChatGPTは数値を見て一般的な解釈を示すことはできますが、個々の患者の背景を考慮した細かな判断はできません。

患者背景の考慮も不十分です。同じ症状でも、年齢、既往歴、内服薬、生活背景によって鑑別診断は変わります。ChatGPTはこうした個別性を十分に考慮できません。

さらに、稀な疾患や複雑な症例には対応できません。ChatGPTは学習データに多く含まれる一般的な疾患については精度が高いですが、稀な疾患や複数の疾患が重なった複雑な症例では、誤った診断を示す可能性があります。

### 5.3 診断支援としての活用法

ChatGPTを診断支援として活用する場合、どのような使い方が適切でしょうか。

最も有効な使い方は、鑑別診断の漏れチェックです。医師がすでに診断をある程度絞り込んでいる段階で、「他に考えるべき鑑別診断はないか」をChatGPTに確認することで、見落としを防げます。ただし、患者の個人情報は絶対に入力せず、「60代男性、胸痛、発汗」といった匿名化された情報のみを使用してください。

また、稀な疾患の情報収集にも使えます。「この症状パターンで考えるべき稀な疾患を教えてください」と質問すれば、教科書的な鑑別診断のリストを提示してくれます。実際にその疾患が当てはまるかは医師が判断する必要がありますが、思い出すきっかけにはなります。

医学生や研修医の学習ツールとしても有効です。症例を入力して鑑別診断を考える練習をする際、ChatGPTに鑑別診断を挙げさせ、それぞれの疾患の特徴を説明させることで、学習効率を高められます。

ただし、診断支援として使う際の注意点があります。まず、ChatGPTの回答を最終診断にしてはいけません。あくまで参考情報として使い、最終的な診断は医師が行います。

また、緊急性の判断はChatGPTに任せてはいけません。「この症状は緊急性があるか」という質問に対する回答は、実際の患者の状態を見ていないため信頼できません。緊急性の判断は必ず医師が行ってください。

そして、ChatGPTの回答には必ずハルシネーション（誤情報）が含まれる可能性があることを忘れないでください。信頼できる医療情報源で確認する習慣をつけましょう。

### 5.4 絶対にやってはいけないこと

医療診断に関して、ChatGPTを使う際に絶対にやってはいけないことを明確にします。

まず、患者の個人情報をそのまま入力してはいけません。氏名、生年月日、住所、カルテ番号などの個人を特定できる情報は、絶対に入力しないでください。これは厚生労働省のガイドラインに違反するだけでなく、個人情報保護法違反にもなります。

次に、ChatGPTの診断を鵜呑みにして治療を開始してはいけません。ChatGPTはハルシネーションを起こす可能性があり、誤った診断を自信を持って提示することがあります。患者に健康被害が生じた場合、医療過誤として責任を問われます。

また、ChatGPTだけに頼って鑑別診断を決定してはいけません。ChatGPTは一般的な鑑別診断は示せますが、個々の患者の背景や身体診察所見、検査結果を総合的に判断することはできません。診断は必ず医師が行ってください。

投与量の確認をChatGPTだけで行うことも危険です。ChatGPTは投与量を誤って回答することがあります。実際に「この薬の投与量を教えてください」と質問したところ、添付文書と異なる投与量を回答した事例が報告されています。投与量は必ず添付文書で確認してください。

患者にChatGPTの診断を直接伝えることも避けるべきです。「ChatGPTによると〜」という説明は、患者に不安を与えるだけでなく、医療者としての責任を回避しているように受け取られます。診断は医師の責任において行い、説明してください。

### 5.5 最終判断は必ず人間が行う原則

医療AIの活用において最も重要な原則は、最終判断は必ず人間が行うということです。

ChatGPTはあくまで「支援ツール」であり、「意思決定者」ではありません。鑑別診断のリストを提示したり、情報を整理したりすることはできますが、患者の命に関わる判断を下すのは人間である医療従事者の責任です。

この原則が重要な理由はいくつかあります。まず、AIは責任を負えません。ChatGPTの回答に基づいて医療行為を行い、患者に健康被害が生じた場合、責任を負うのは医療従事者です。「AIがそう言ったから」という言い訳は法的に通用しません。

次に、AIは患者を総合的に診ることができません。医療は単なる疾患の治療ではなく、患者の背景、価値観、希望を考慮した全人的な医療が求められます。患者の不安を理解し、共感し、最適な治療方針を一緒に考えることは、人間にしかできません。

また、AIは倫理的判断ができません。終末期医療の方針、延命治療の選択、臓器移植の優先順位など、医療には倫理的判断が求められる場面が多くあります。これらの判断には、人間の価値観と倫理観が不可欠です。

さらに、医療は常に変化する分野です。新しいエビデンスが発表され、ガイドラインが更新され、治療法が進化します。AIの学習データは一定時点のものであり、最新の医療知識に追いついていません。医療従事者は常に最新の情報を学び、判断を更新する必要があります。

最終判断を人間が行うための具体的な方法は、ChatGPTの回答を参考情報として扱い、必ず信頼できる医療情報源で確認することです。添付文書、診療ガイドライン、信頼できる医学データベース（UpToDate、DynaMed、今日の臨床サポートなど）で情報を確認してください。

また、わからないことは専門家に相談することです。ChatGPTに頼るのではなく、専門医にコンサルトしたり、カンファレンスで議論したりすることが、正確な診断につながります。

そして、患者とのコミュニケーションを大切にすることです。患者の訴えをよく聞き、不安を理解し、一緒に治療方針を考える姿勢が、AIには代替できない医療者の価値です。

## 第6章: 医療現場でのChatGPT活用5大リスクと対策

### 6.1 個人情報漏洩のリスク（患者情報は絶対NG）

医療現場でChatGPTを使う際の最大のリスクは、個人情報の漏洩です。患者の個人情報をChatGPTに入力すれば、それは海外のサーバーに送信され、30日間保存されます。

個人情報漏洩のリスクが高い理由は、まずデータが海外サーバーに保存されることです。ChatGPTのサーバーはアメリカにあり、日本の個人情報保護法の管轄外です。また、サイバー攻撃によってデータが漏洩する可能性もゼロではありません。

さらに、30日間のログ保存期間中に何が起きるかわかりません。OpenAI社は不正利用の監視のためにログを確認すると説明していますが、その過程で個人情報が第三者の目に触れる可能性があります。

対策として最も重要なのは、患者の個人情報を絶対に入力しないことです。氏名、生年月日、住所、電話番号、カルテ番号、保険証番号など、個人を特定できる情報は絶対に入力してはいけません。

もし患者情報を扱う必要がある場合は、完全に匿名化してください。「70代女性、糖尿病、HbA1c 8.5%」といった形で、個人を特定できない情報のみを使用します。年齢は「70代」のように幅を持たせ、地名も「関東地方」といった広い範囲で表現してください。

また、スクリーンショットにも注意が必要です。電子カルテの画面をスクリーンショットしてChatGPTに画像としてアップロードすると、画像から個人情報が読み取られてしまいます。画像にも患者の個人情報を含めないでください。

さらに、医療機関全体でルールを作ることも必要です。個人情報を入力してはいけないという原則を全スタッフに周知し、違反者には懲戒処分を科すという明確なルールを設けるべきです。

### 6.2 ハルシネーション（誤情報生成）への対処法

ChatGPTの大きな問題の一つが、ハルシネーション（誤情報の生成）です。ハルシネーションとは、AIが自信を持って間違った情報を提示することを指します。

医療現場で特に危険なのは、投与量の誤りです。「この薬の投与量を教えてください」と質問したところ、添付文書とは異なる投与量を回答した事例が報告されています。しかも、その回答は具体的で自信に満ちているため、医療従事者でも誤情報と気づかないことがあります。

また、禁忌事項の誤りもあります。「この薬は腎機能低下患者に使えますか」という質問に対し、実際には禁忌なのに「使用可能です」と回答することがあります。これを鵜呑みにして処方すれば、患者に健康被害が生じます。

さらに、存在しない研究論文を引用することもあります。「〜という研究によると」と具体的な著者名や雑誌名を挙げて回答しますが、実際にはそのような論文は存在しません。このため、ChatGPTが引用する論文は必ず実在するか確認する必要があります。

ハルシネーションへの対処法は、まず疑う習慣を持つことです。ChatGPTの回答を鵜呑みにせず、「本当にこれは正しいか」と常に疑問を持ってください。特に投与量、禁忌、相互作用などの重要な情報は、必ず確認が必要です。

次に、信頼できる情報源で確認することです。添付文書、診療ガイドライン、医学データベース（UpToDate、DynaMed、今日の臨床サポートなど）で情報を確認する習慣をつけてください。ChatGPTはあくまで下書き作成や情報整理のツールであり、最終的な情報源ではありません。

また、複数の情報源でクロスチェックすることも有効です。ChatGPTの回答が正しいか、他の医療情報源でも同じことが書かれているか確認してください。一つの情報源だけに頼ると、誤情報を見逃す可能性があります。

### 6.3 法的責任の問題（医療者が全責任を負う）

ChatGPTを医療現場で使う際の法的責任について、明確にしておく必要があります。結論から言えば、ChatGPTの回答に基づいて医療行為を行った結果、患者に健康被害が生じた場合、責任を負うのは医療従事者です。

「ChatGPTがそう言ったから」という言い訳は法的に通用しません。医療行為の責任は、それを実施した医療従事者が負います。ChatGPTは単なるツールであり、責任の主体にはなりません。

具体的な責任の例を見てみましょう。まず、誤った投与量を処方した場合、医療過誤として訴えられる可能性があります。ChatGPTが誤った投与量を回答し、それを確認せずに処方した結果、患者に健康被害が生じれば、処方した医師の責任です。

次に、禁忌の薬剤を処方した場合も同様です。ChatGPTが「この薬は使用可能」と回答したが、実際には禁忌だった場合、それを確認しなかった医師の責任が問われます。

また、個人情報を漏洩させた場合、個人情報保護法違反として罰せられます。患者の個人情報をChatGPTに入力し、それが第三者に漏洩した場合、医療機関と医療従事者個人の両方が責任を問われます。

法的責任を回避するための対策は、まず最終確認を徹底することです。ChatGPTの回答は必ず信頼できる情報源で確認し、自分の判断で正しいと確信してから実施してください。

次に、院内ルールを明確にすることです。ChatGPTの使用範囲、個人情報の取り扱い、確認手順などを明確に定め、全スタッフに周知してください。ルールを守らなかった場合の懲戒処分についても明記すべきです。

また、記録を残すことも必要です。ChatGPTを使用した場合、その内容と確認手順を記録に残してください。万が一トラブルが発生した場合、適切な手順を踏んでいたことを証明できます。

### 6.4 データセキュリティの確保

医療現場でChatGPTを使う際のデータセキュリティについて考えます。

まず、通信の暗号化は確保されています。ChatGPTはHTTPS通信を使用しており、通信内容は暗号化されています。このため、通信途中でデータが傍受される可能性は低いです。

しかし、問題はデータの保存期間です。前述の通り、ChatGPTは30日間ログを保存します。この期間中にOpenAI社のサーバーがサイバー攻撃を受ける可能性はゼロではありません。

また、端末のセキュリティも必要です。ChatGPTを使用する端末が紛失したり盗難に遭ったりすれば、チャット履歴から情報が漏洩する可能性があります。

データセキュリティを確保するための対策は、まず端末管理を徹底することです。ChatGPTを使用する端末には、パスワードや生体認証でロックをかけ、紛失時には遠隔でデータを消去できるようにしてください。

次に、チャット履歴を定期的に削除することです。ChatGPTの設定から、過去のチャット履歴を削除できます。必要のない履歴は定期的に削除し、データが残らないようにしてください。

また、公共のWi-Fiは使用しないことです。病院外でChatGPTを使う場合、公共のWi-Fiはセキュリティリスクが高いため避けてください。モバイルデータ通信か、セキュリティが確保されたWi-Fiを使用してください。

さらに、医療機関向けのEnterpriseプランの導入を検討することも一案です。OpenAI社はEnterpriseプランを提供しており、データ保持期間の短縮や、専用のセキュリティ設定が可能です。医療機関全体でChatGPTを活用する場合、Enterpriseプランの導入を検討する価値があります。

### 6.5 偏った情報・差別的表現のリスク

ChatGPTは、学習データに含まれる偏りや差別的表現を反映する可能性があります。

医療現場で問題になるのは、特定の人種や性別に対する偏った情報です。例えば、ある疾患の診断において、人種によって症状の出方が異なるにもかかわらず、特定の人種の情報しか提示しないことがあります。

また、高齢者に対する偏見も問題です。「高齢者は理解力が低い」といった偏見に基づいた説明文を生成することがあります。実際には高齢者でも理解力の高い人は多く、一律に「わかりやすく」説明すれば良いわけではありません。

さらに、性別による偏りもあります。特定の疾患について、男性の症例ばかりを説明し、女性の症状の違いに言及しないことがあります。心筋梗塞などは男女で症状が異なることがありますが、ChatGPTがこれを十分に説明しないことがあります。

偏った情報への対策は、まずChatGPTの回答を批判的に読むことです。「この説明は特定の集団に偏っていないか」「すべての患者に当てはまる情報か」を常にチェックしてください。

次に、多様性を意識して質問することです。「この疾患について、高齢者、女性、アジア人それぞれの特徴を教えてください」といった形で、多様な視点を求める質問をしてください。

また、患者の個別性を尊重することです。ChatGPTの回答は一般論ですが、実際の患者は一人一人異なります。年齢、性別、人種、文化、価値観などを考慮し、個別に対応してください。

### 6.6 安全に使うための院内ルール作り

医療機関全体でChatGPTを安全に使うためには、明確な院内ルールが必要です。

ルールに含めるべき項目は、まず使用範囲の明確化です。どのような用途でChatGPTを使って良いのか、使ってはいけないのかを明確にします。例えば、「文献検索、勉強会資料作成には使用可能。電子カルテ情報の入力は禁止」といった形です。

次に、個人情報の取り扱いルールです。患者の個人情報は絶対に入力しない、匿名化する場合の基準、違反した場合の懲戒処分などを明記します。

また、確認手順の義務化も必要です。ChatGPTの回答を医療行為に使う場合、必ず信頼できる情報源で確認することを義務付けます。確認を怠った場合の責任も明確にしてください。

さらに、研修の実施も必要です。全スタッフにChatGPTのリスクと安全な使い方を研修し、ルールを周知します。定期的に研修を実施し、最新の情報を共有してください。

加えて、トラブル発生時の対応手順も定めます。万が一、個人情報を入力してしまった場合、誤情報に基づいて医療行為を行ってしまった場合など、トラブル発生時の報告先と対応手順を明確にしてください。

院内ルール作りのポイントは、現場の意見を取り入れることです。医師、看護師、薬剤師、医療事務など、各職種の意見を聞き、実際に使いやすいルールを作ってください。厳しすぎるルールは守られませんし、緩すぎるルールはリスクが高まります。

また、ルールは定期的に見直すことも必要です。ChatGPTの機能は日々進化し、厚生労働省のガイドラインも更新されます。これらの変化に合わせて、ルールも更新してください。

## 第7章: ChatGPT医療統計・データ分析活用法

### 7.1 Advanced Data Analysis機能の使い方

ChatGPTの有料版（ChatGPT Plus）には、Advanced Data Analysis機能（旧Code Interpreter）が搭載されています。この機能を使えば、データファイルをアップロードして統計解析を実行できます。

Advanced Data Analysis機能の基本的な使い方は、まずChatGPTの画面で機能を有効にします。チャット入力欄の横にある「+」マークをクリックし、「Advanced Data Analysis」を選択します。すると、ファイルをアップロードできるようになります。

次に、解析したいデータファイル（CSV、Excel、テキストファイルなど）をアップロードします。ただし、患者の個人情報を含むデータは絶対にアップロードしないでください。匿名化されたデータ、または仮想データのみを使用してください。

データをアップロードしたら、ChatGPTに解析の指示を出します。「このデータの記述統計を出してください」「年齢と血圧の相関を調べてください」「群間比較のt検定を実行してください」といった指示です。

ChatGPTはPythonのプログラムを自動的に作成し、実行して結果を表示してくれます。グラフの作成も可能で、「ヒストグラムを作成してください」「散布図を描いてください」といった指示にも対応します。

医療現場での活用例としては、臨床研究のデータ解析があります。少数例の症例報告や後ろ向き研究のデータを解析し、記述統計や基本的な検定を実行できます。ただし、結果の解釈は必ず統計の専門知識を持つ人が行ってください。

また、診療データの集計にも使えます。ある疾患の患者数、年齢分布、治療内容の集計などを、ChatGPTに依頼して自動化できます。ただし、個人情報を含まないよう、あらかじめデータを匿名化しておくことが必須です。

注意点として、ChatGPTは統計の専門家ではありません。適切な統計手法を選択できないことがあり、解釈を誤ることもあります。Advanced Data Analysis機能はあくまで補助ツールであり、最終的な解析と解釈は人間が行ってください。

### 7.2 医療統計GPTの活用

ChatGPTには「GPTs」という機能があり、特定の用途に特化したカスタムAIを使用できます。その中に「医療統計GPT」というものがあり、医療統計に関する質問に特化した回答を得られます。

医療統計GPTは、一般的なChatGPTよりも医療統計の専門的な知識に詳しく、臨床研究でよく使われる統計手法について正確な説明をしてくれます。

使い方は、ChatGPTのトップ画面から「GPTs」を検索し、「医療統計」と検索すれば見つかります。医療統計GPTを選択して、質問を入力するだけです。

医療統計GPTに質問できる内容は、まず統計手法の選択です。「2群の連続変数を比較したいのですが、どの統計手法を使うべきですか」といった質問に、データの分布や研究デザインに応じた手法を提案してくれます。

また、サンプルサイズの計算についても質問できます。「効果量0.5、検出力0.8で必要なサンプルサイズを教えてください」といった質問に、計算式と結果を示してくれます。

さらに、統計用語の説明も得意です。「p値とは何ですか」「信頼区間の解釈方法を教えてください」「多重比較の調整とは何ですか」といった質問に、医療従事者向けにわかりやすく説明してくれます。

ただし、医療統計GPTもあくまでAIです。複雑な研究デザインや特殊な統計手法については、誤った回答をする可能性があります。重要な臨床研究の統計解析は、必ず統計の専門家（生物統計家、疫学者など）に相談してください。

### 7.3 臨床疑問から統計手法を調査する方法

臨床研究を計画する際、「どの統計手法を使えば良いか」という疑問が生じます。ChatGPTを使えば、この疑問を素早く解決できます。

まず、研究の目的とデザインを明確にします。「新しい治療法の効果を調べたい」「リスク因子を特定したい」「診断精度を評価したい」といった研究の目的を整理してください。

次に、ChatGPTに質問します。具体的な質問例は以下の通りです。

「新薬と従来薬の血圧降下効果を比較したいです。どの統計手法を使うべきですか。データは連続変数で、2群間の比較です。」

「年齢、性別、喫煙歴が心筋梗塞のリスク因子かどうかを調べたいです。どの統計手法が適切ですか。」

「新しい診断マーカーの診断精度を評価したいです。感度、特異度、ROC曲線の作成方法を教えてください。」

ChatGPTは、研究デザイン、データの種類、比較する群の数などに基づいて、適切な統計手法を提案してくれます。t検定、分散分析、カイ二乗検定、ロジスティック回帰分析、生存時間解析など、一般的な統計手法については正確に提案できます。

ただし、ChatGPTの提案を鵜呑みにせず、統計の教科書や専門家の意見で確認することが必要です。特に、データの分布が正規分布でない場合、ノンパラメトリック検定を使うべきかどうかなど、細かな判断は人間が行う必要があります。

また、統計ソフトウェアの使い方についても質問できます。「Rで対応のあるt検定を実行するコードを教えてください」「SPSSでロジスティック回帰分析を行う手順を説明してください」といった質問に、具体的なコードや手順を示してくれます。

### 7.4 データアップロードと解析の実践

実際にデータをChatGPTにアップロードして解析する手順を説明します。ただし、繰り返しますが、患者の個人情報を含むデータは絶対にアップロードしないでください。

まず、データを準備します。患者ID、氏名、生年月日などの個人情報は削除し、匿名化された形でデータを作成してください。ExcelまたはCSV形式で保存します。

次に、ChatGPT Plusを開き、Advanced Data Analysis機能を有効にします。画面左下の「+」マークから「Advanced Data Analysis」を選択してください。

データファイルをアップロードします。ファイルアイコンをクリックして、準備したデータファイルを選択します。

ChatGPTに解析の指示を出します。具体例を見てみましょう。

「このデータの記述統計を出してください。平均、標準偏差、最小値、最大値を表示してください。」

「年齢と血圧の散布図を作成してください。相関係数も計算してください。」

「治療群と対照群の血圧を比較してください。t検定を実行して、p値を報告してください。」

ChatGPTはPythonのプログラムを自動的に作成し、実行して結果を表示します。グラフも自動的に作成され、画像として表示されます。

結果が表示されたら、内容を確認します。記述統計の値が妥当か、グラフが正しく描画されているか、統計検定の結果が解釈可能かをチェックしてください。

もし結果がおかしい場合は、ChatGPTに追加の指示を出します。「年齢の外れ値を削除して再度解析してください」「対数変換してから相関を調べてください」といった指示で、解析を修正できます。

ただし、ChatGPTの解析結果を論文や報告書に使う場合は、必ず統計の専門家に確認してもらってください。ChatGPTは便利なツールですが、統計の専門知識を持つ人間の確認が不可欠です。

### 7.5 統計知識は依然として必要な理由

ChatGPTで統計解析ができるからといって、統計の勉強が不要になるわけではありません。むしろ、統計の基本的な知識がなければ、ChatGPTを正しく使うことはできません。

まず、適切な統計手法を選ぶには、研究デザインとデータの性質を理解する必要があります。データが正規分布に従っているか、対応のあるデータか独立したデータか、サンプルサイズは十分かなど、多くの要因を考慮しなければなりません。ChatGPTはこれらの判断を完全には行えません。

次に、結果の解釈には統計の知識が不可欠です。p値が0.05未満だからといって、必ずしも臨床的に意味のある差があるとは限りません。効果量、信頼区間、臨床的意義を総合的に判断する必要があります。

また、ChatGPTのミスを見抜くにも統計の知識が必要です。ChatGPTは時々誤った統計手法を提案したり、誤った解釈を示したりします。これを見抜くには、自分自身が統計の基本を理解していなければなりません。

さらに、臨床研究では複雑な研究デザインが必要になることがあります。クロスオーバー試験、傾向スコアマッチング、多重比較の調整、生存時間解析など、高度な統計手法はChatGPTだけでは正しく実施できません。

医療従事者が統計を学ぶべき理由は、論文を批判的に読むためでもあります。医学論文には統計解析の結果が多く含まれており、これを正しく理解するには統計の知識が必要です。「この研究のサンプルサイズは十分か」「この統計手法は適切か」「結果は信頼できるか」を判断するには、統計の基礎を学ぶ必要があります。

ChatGPTは統計学習の補助ツールとしても有効です。わからない統計用語をChatGPTに質問したり、統計手法の選択肢を提案してもらったり、計算の確認をしたりすることで、学習効率を高められます。しかし、最終的には自分自身で統計を理解し、判断できる力が必要です。

医療従事者向けの統計学習リソースとしては、書籍（「医学統計がわかる」「臨床研究の道標」など）、オンライン講座（Coursera、Udemyなど）、医療統計セミナーなどがあります。これらを活用して、基本的な統計知識を身につけてください。

## 第8章: 医療向けAIツール・アプリの使い分け

### 8.1 ChatGPT vs Gemini vs Claude（医療現場での比較）

医療現場では、ChatGPT以外にもGeminiやClaudeといった生成AIツールが使えます。それぞれの特徴を理解し、用途に応じて使い分けることが必要です。

ChatGPTの強みは、汎用性と使いやすさです。文章生成、要約、翻訳など幅広い用途に対応でき、医療従事者の多くが使い慣れています。有料版のAdvanced Data Analysis機能を使えば、データ解析も可能です。一方で、最新情報への対応は限定的（無料版は2021年9月まで）で、Web検索機能を使わない限り新しい情報は得られません。

Geminiの強みは、Google検索との連携です。最新の医療情報を検索しながら回答を生成できるため、新しいガイドラインや最近の研究動向を調べるのに適しています。また、GeminiのDeep Research機能を使えば、複数の情報源を調査して包括的なレポートを作成してくれます。「SGLT2阻害薬の最新エビデンス」といったテーマを依頼すれば、複数の論文やニュース記事を調査し、まとめてくれます。

Claudeの強みは、長文の処理能力と安全性への配慮です。長い医学論文や診療ガイドライン全文を入力して要約するできます。また、医療倫理や個人情報保護に関する配慮が強く、不適切な質問には回答を拒否する傾向があります。ただし、Claudeも30日間ログを保存するため、電子カルテ情報の入力は避けるべきです。

業務シーン別の使い分けとしては、文献検索と最新情報の調査にはGeminiが適しています。診断書や紹介状の下書き作成にはChatGPTが使いやすいです。長文の論文や診療ガイドラインの要約にはClaudeが優れています。

ただし、どのツールを使う場合でも、個人情報は絶対に入力しない、回答は必ず確認するという原則は同じです。AIツールの選択よりも、正しい使い方を理解することが必要です。

### 8.2 HOKUTO（臨床支援アプリ）の活用

HOKUTOは、医師向けの臨床支援アプリです。診療ガイドライン、添付文書、医学論文などの医療情報を素早く検索でき、日常診療の場で活用できます。

HOKUTOの基本機能は、まず診療ガイドラインの検索です。日本のすべての学会ガイドラインが収録されており、疾患名やキーワードで検索できます。診察中にガイドラインを確認したい場合、スマートフォンで素早く調べられます。

また、添付文書の検索も可能です。薬剤名を入力すれば、添付文書の全文を表示してくれます。投与量、禁忌、副作用などを確認する際に便利です。

さらに、医学論文の検索もできます。PubMedと連携しており、キーワードで論文を検索し、アブストラクトを表示してくれます。日本語で検索しても、自動的に英語に変換して検索してくれるため、英語が苦手な医師でも使いやすいです。

HOKUTOの新機能として、GPT-4を活用したAI機能が追加されました。医療情報を検索する際、AIが関連する情報を提案してくれます。例えば、「心不全」と検索すれば、関連する診療ガイドライン、治療薬、最新の論文などを自動的に提示してくれます。

HOKUTOの利点は、医療に特化した情報源であることです。一般的なChatGPTはインターネット全体から学習していますが、HOKUTOは診療ガイドラインや添付文書といった信頼できる医療情報のみを扱っています。このため、情報の信頼性が高いです。

また、個人情報保護の観点でも安心です。HOKUTOは情報を検索するだけで、患者情報を入力する機能はありません。このため、個人情報漏洩のリスクが低いです。

HOKUTOは基本無料で使えますが、一部の機能は有料プランが必要です。医師であれば登録可能で、看護師や薬剤師も一部の機能を利用できます。

### 8.3 医師向け推奨9ツール

医療現場でAIツールを活用したい医師に向けて、推奨ツール9つを紹介します。

1つ目は、ChatGPTです。汎用性が高く、文章作成、要約、翻訳など幅広い用途に使えます。有料版（ChatGPT Plus）ならAdvanced Data Analysis機能でデータ解析も可能です。

2つ目は、Gemini（旧Bard）です。Google検索と連携しており、最新の医療情報を調べるのに適しています。Deep Research機能を使えば、包括的な調査レポートを作成してくれます。

3つ目は、Claudeです。長文の処理能力が高く、医学論文や診療ガイドライン全文を要約できます。

4つ目は、HOKUTOです。診療ガイドライン、添付文書、医学論文を素早く検索できる医師向け臨床支援アプリです。

5つ目は、UpToDateです。エビデンスに基づいた臨床情報を提供する有料データベースです。最新の診療情報を調べる際の標準的なツールです。

6つ目は、今日の臨床サポートです。日本語の臨床情報データベースで、疾患の診断、治療、薬剤情報などを検索できます。

7つ目は、PubMedです。医学論文の検索データベースです。無料で使え、世界中の医学論文を検索できます。

8つ目は、Mendeleyです。論文管理ツールで、収集した論文を整理し、引用文献を自動生成できます。

9つ目は、Notionです。メモや資料を整理するツールで、AIアシスタント機能を使えば、メモの要約や資料作成を補助してくれます。

これらのツールを組み合わせて使うことで、文献検索から論文管理、資料作成まで、一連の作業を効率化できます。ただし、どのツールも万能ではありません。最終的な判断は必ず自分で行ってください。

### 8.4 無料スマホアプリ3選

スマートフォンで使える無料の医療AIアプリを3つ紹介します。

1つ目は、ChatGPTのスマホアプリです。iOSとAndroidの両方で提供されており、無料で使えます。診療中に素早く情報を調べたり、文章を作成したりする際に便利です。音声入力にも対応しているため、手が空いていない状況でも使えます。

2つ目は、Geminiのスマホアプリです。Google検索と連携しており、最新の医療情報を調べるのに適しています。無料で使え、日本語にも対応しています。

3つ目は、HOKUTOのスマホアプリです。診療ガイドライン、添付文書、医学論文を素早く検索できます。基本機能は無料で、医師登録すれば全機能を使えます。

これらのアプリはすべて無料（一部機能は有料）で使えるため、まずは試してみて、自分の業務に合ったものを選んでください。ただし、患者情報を入力してはいけないという原則は、どのアプリでも同じです。

### 8.5 業務シーン別おすすめツール

医療従事者の業務シーン別に、おすすめのAIツールを整理します。

文献検索の場合、まずPubMedで論文を検索し、興味深い論文が見つかったらChatGPTまたはClaudeでアブストラクトを要約します。最新の研究動向を調べる場合は、GeminiのDeep Research機能を使って包括的なレポートを作成します。

診断書や紹介状の作成には、ChatGPTが適しています。テンプレートを作成させ、実際の患者情報は自分で追記します。ただし、患者の個人情報は絶対に入力しないでください。

患者向け説明資料の作成にも、ChatGPTが便利です。専門用語を平易な言葉に言い換えたり、わかりやすい説明文を作成したりする際に活用できます。

診療ガイドラインの確認には、HOKUTOまたはUpToDateが適しています。診察中に素早くガイドラインを確認できます。

統計解析には、ChatGPTのAdvanced Data Analysis機能が使えます。ただし、患者の個人情報を含むデータは絶対にアップロードしないでください。匿名化されたデータのみを使用します。

勉強会資料の作成には、ChatGPTで構成案を作成し、各セクションの詳細をChatGPTに生成させます。その後、最新のガイドラインや文献で内容を確認・修正します。

論文執筆には、Mendeleyで論文を管理し、ChatGPTで英文校正や要約を依頼します。ただし、論文の核心部分は自分で書き、ChatGPTはあくまで補助ツールとして使ってください。

業務シーン別にツールを使い分けることで、効率を最大化できます。ただし、どのツールを使う場合でも、個人情報保護と最終確認の原則は守ってください。

## 第9章: 医療現場でのChatGPT成功事例と失敗事例

### 9.1 診断書作成時間が10分の1に（成功事例）

ある診療所では、ChatGPTを診断書作成に活用し、作成時間を従来の10分の1に短縮することに成功しました。

この診療所では、これまで診断書の作成に1通あたり20〜30分かかっていました。特に複雑な病状を説明する診断書では、適切な表現を考えるのに時間がかかっていました。

導入方法は、まずChatGPTに診断書のテンプレートを作成させました。「高血圧症の診断書のテンプレート」「腰痛症の診断書のテンプレート」といった形で、よく使う診断書の基本構成を作成しておきました。

実際の診断書作成時には、このテンプレートを呼び出し、患者固有の情報（病歴、検査結果、治療内容など）を医師が追記します。患者の個人情報は一切ChatGPTに入力せず、すべて医師が手作業で追記しました。

この方法により、診断書作成時間が3〜5分に短縮され、医師は患者とのコミュニケーションにより多くの時間を使えるようになりました。また、診断書の表現が統一され、わかりやすくなったという患者からの評価も得られました。

成功のポイントは、患者情報を入力しないという原則を徹底したこと、テンプレートを事前に作成しておいたこと、医師が最終確認を必ず行ったことです。

### 9.2 文献検索の効率化事例

ある大学病院の医師は、ChatGPTを文献検索に活用し、情報収集の効率を大幅に向上させました。

この医師は、毎週の抄読会で最新の医学論文を紹介する担当でしたが、多数の英語論文を読むのに時間がかかっていました。特に、自分の専門外の論文では、内容を理解するのに苦労していました。

ChatGPTの活用方法は、まずPubMedで関連する論文を検索し、興味深い論文を10〜20本ピックアップします。次に、各論文のアブストラクトをChatGPTに入力し、「この論文の要点を日本語で3つにまとめてください」と依頼します。

ChatGPTが要約を提示したら、その中から特に興味深い論文を選び、全文を精読します。これにより、すべての論文を精読する必要がなくなり、時間を大幅に短縮できました。

また、専門用語の理解にもChatGPTを活用しました。わからない医学用語があれば、「この用語を日本語でわかりやすく説明してください」と質問し、理解を深めました。

この方法により、文献検索にかかる時間が従来の半分以下になり、より多くの論文をチェックできるようになりました。抄読会でも、より幅広いトピックを紹介できるようになりました。

成功のポイントは、ChatGPTを一次スクリーニングのツールとして使い、重要な論文は必ず原文を確認したこと、専門用語の理解を深めるツールとして活用したことです。

### 9.3 患者コミュニケーション改善事例

ある病院の看護師は、ChatGPTを活用して患者向け説明資料を作成し、患者とのコミュニケーションを改善しました。

この看護師は、手術前の説明や退院指導の際、患者さんに説明する内容をわかりやすく伝えるのに苦労していました。特に高齢の患者さんや、医療知識のない患者さんには、専門用語を避けた平易な説明が必要でした。

ChatGPTの活用方法は、まず説明したい内容を箇条書きでメモします。次に、ChatGPTに「以下の内容を、高齢者にもわかりやすいように説明する資料を作成してください」と依頼します。

ChatGPTは、専門用語を避け、具体的な例を交えた説明文を生成してくれます。例えば、「抗凝固薬」を「血液をサラサラにする薬」に、「空腹時服用」を「食事の前に飲んでください」といった形で言い換えてくれます。

看護師は、ChatGPTが作成した説明文を確認・修正し、患者さんに配布します。この資料を使って説明することで、患者さんの理解度が大幅に向上しました。

また、患者さんからの質問に対する回答も、ChatGPTを使って準備しました。「この薬を飲み忘れたらどうすればよいか」「副作用が出たらどうすればよいか」といった質問を想定し、事前にわかりやすい回答を準備しておきました。

この方法により、患者さんからの「わかりやすかった」という評価が増え、退院後の服薬アドヒアランスも向上しました。

成功のポイントは、専門用語を平易な言葉に言い換えたこと、具体例を交えて説明したこと、ChatGPTの回答を必ず看護師が確認・修正したことです。

### 9.4 投与量を間違えて提供された失敗事例

一方で、ChatGPTの誤情報を鵜呑みにして失敗した事例もあります。ある医療機関では、ChatGPTが提示した誤った投与量をそのまま使用しかけました。

この医療機関の医師は、ある薬剤の投与量を確認するため、ChatGPTに「この薬の通常投与量を教えてください」と質問しました。ChatGPTは、具体的な投与量を数値で回答しました。

医師はこの回答を信じて処方箋を書こうとしましたが、たまたま薬剤師が疑問に思い、添付文書を確認したところ、ChatGPTが提示した投与量が誤っていることが判明しました。実際の投与量は、ChatGPTが提示した量の半分でした。

もし薬剤師が確認しなければ、患者に過量投与してしまうところでした。幸い、事前に気づいたため健康被害には至りませんでしたが、医療機関内で大きな問題となりました。

この事例から学ぶべき教訓は、ChatGPTの回答を鵜呑みにしてはいけないということです。特に投与量、禁忌、副作用など、患者の安全に関わる情報は、必ず信頼できる情報源（添付文書、診療ガイドライン、医学データベースなど）で確認する必要があります。

また、医療機関全体で確認体制を整えることも必要です。医師が処方した内容を薬剤師が確認する、看護師がダブルチェックするといった仕組みがあれば、ミスを防げます。

この医療機関では、この事例を受けて、「ChatGPTを薬剤情報の確認に使用することを禁止する」という院内ルールを設けました。ChatGPTは文献検索や資料作成には使えますが、投与量の確認には使わないというルールです。

### 9.5 個人情報を入力してしまった失敗事例

別の医療機関では、医療従事者が誤って患者の個人情報をChatGPTに入力してしまう事例がありました。

この医療機関の医師は、複雑な症例について相談するため、患者の病歴をChatGPTに入力しました。その際、患者の氏名や年齢、住所などの個人情報も含めて入力してしまいました。

後日、この医師は個人情報を入力してしまったことに気づき、医療機関の管理部門に報告しました。医療機関は直ちにOpenAI社に連絡し、データの削除を依頼しましたが、30日間はログが保存されるため、完全な削除はできませんでした。

幸い、この情報が外部に漏洩した形跡はありませんでしたが、医療機関は個人情報保護委員会に報告し、再発防止策を講じることになりました。また、この医師は院内で懲戒処分を受けました。

この事例から学ぶべき教訓は、個人情報は絶対に入力してはいけないということです。たとえ複雑な症例で相談したい場合でも、患者を特定できる情報はすべて削除し、完全に匿名化してから入力する必要があります。

また、医療機関全体で教育を徹底することも必要です。すべての医療従事者にChatGPTのリスクと正しい使い方を研修し、個人情報保護の重要性を周知する必要があります。

この医療機関では、この事例を受けて、AI使用に関する研修を全スタッフに実施し、違反した場合は懲戒処分を科すという厳格なルールを設けました。

### 9.6 事例から学ぶ活用のポイント

これらの成功事例と失敗事例から、ChatGPTを医療現場で安全に活用するためのポイントをまとめます。

まず、個人情報は絶対に入力しないという原則を徹底してください。どんなに便利でも、患者の個人情報を入力してはいけません。完全に匿名化した情報のみを使用してください。

次に、ChatGPTの回答は必ず確認してください。特に投与量、禁忌、副作用など、患者の安全に関わる情報は、必ず信頼できる情報源で確認してください。ChatGPTは便利なツールですが、誤情報を提供する可能性があります。

また、医療機関全体でルールを作り、研修を実施してください。個人の判断だけに任せるのではなく、医療機関全体で明確なルールを設け、全スタッフに周知してください。

さらに、ChatGPTを「支援ツール」として使い、「意思決定者」として使わないでください。診断書の下書き、文献の要約、説明資料の作成など、補助的な用途に限定し、最終的な判断は必ず人間が行ってください。

そして、失敗事例を共有し、学び合うことも必要です。他の医療機関での失敗事例を知ることで、同じミスを繰り返さないようにできます。医療機関同士で情報を共有し、安全なAI活用を進めてください。

これらのポイントを守ることで、ChatGPTを安全に活用し、医療の質と効率を向上させるできます。

## 第10章: 医療AIの今後と医療従事者が身につけるべきスキル

### 10.1 医療AIの進化予測（2025年以降）

医療AIは今後さらに進化していくと予測されます。2025年以降の医療AI動向について考えてみましょう。

まず、生成AIの精度向上が期待されます。ChatGPTは2025年8月にGPT-5に統一されましたが、今後もモデルの性能は向上し続けるでしょう。医療情報のハルシネーション（誤情報）が減少し、より信頼性の高い回答が得られるようになると期待されます。

次に、医療特化型AIの登場が予想されます。現在のChatGPTは汎用的なAIですが、今後は医療に特化したAIが開発されるでしょう。医学論文や診療ガイドラインを重点的に学習し、医療従事者の業務により適した回答を提供するAIが登場する可能性があります。

また、リアルタイム情報への対応も進むでしょう。現在のChatGPTは学習データの期限がありますが、今後はリアルタイムで最新の医療情報にアクセスできるようになる可能性があります。最新のガイドライン改定や新薬の承認情報を即座に反映できるAIが実現するでしょう。

さらに、音声認識との統合も進展すると予想されます。診察中に音声で質問し、AIが音声で回答するシステムが実用化されれば、診療の効率がさらに向上します。すでに音声入力機能は実装されていますが、今後はより自然な対話が可能になるでしょう。

画像診断AIとの統合も期待されます。CTやMRIの画像をAIが解析し、診断支援を行う技術はすでに実用化されていますが、今後はChatGPTのような生成AIと統合され、画像所見を自動的に文章化するシステムが登場する可能性があります。

電子カルテとの連携も進む可能性があります。現在は個人情報保護の観点から電子カルテ情報をChatGPTに入力できませんが、今後は医療機関向けの専用AIが開発され、セキュアな環境で電子カルテ情報を活用できるようになる可能性があります。

ただし、これらの進化は必ずしもすべて実現するとは限りません。技術的な課題だけでなく、法規制、倫理的問題、コストなど、多くの要因が関わります。医療従事者は技術の進化を注視しつつ、現実的な活用方法を模索する必要があります。

### 10.2 厚生労働省の規制動向

厚生労働省の医療AI規制は今後も変化していくと予想されます。

2023年5月にガイドライン第6.0版が策定され、2025年5月にQ&Aが更新されて電子カルテ情報の取り扱いが厳格化されました。今後もAI技術の進化に合わせて、規制が更新されていくでしょう。

予想される規制の方向性として、まず個人情報保護の強化があります。患者のプライバシーを守るため、医療情報の取り扱いはより厳格になる可能性があります。海外サーバーへのデータ送信規制、ログ保存期間の制限など、より厳しいルールが設けられる可能性があります。

次に、医療AIの品質管理基準の策定が考えられます。医療機器としてのAI承認プロセス、診断支援AIの精度基準、医療従事者向けAIの使用ガイドラインなど、AIの品質を担保する仕組みが整備されるでしょう。

また、医療従事者のAI教育義務化の可能性もあります。AIを安全に使うための知識とスキルを、医療従事者に習得させる制度が導入される可能性があります。医師国家試験や看護師国家試験にAI関連の問題が出題されることも考えられます。

さらに、医療AIに関する責任の明確化も進むでしょう。AIの誤情報によって医療事故が発生した場合、誰が責任を負うのか、医療従事者なのか、AI開発者なのか、医療機関なのか、といった問題を明確にする法整備が進むと予想されます。

医療従事者は、これらの規制動向を常に把握しておく必要があります。厚生労働省のウェブサイト、医療AIに関するガイドライン、医療安全情報などを定期的にチェックし、最新の規制に対応してください。

また、医療機関全体で規制への対応体制を整えることも必要です。AI使用ルールを定期的に見直し、法規制の変化に合わせて更新してください。

### 10.3 医療従事者がAIと共存するために必要なスキル

AIと共存する時代に、医療従事者が身につけるべきスキルについて考えます。

まず、AIリテラシーが必要です。AIとは何か、どのような仕組みで動いているのか、何が得意で何が苦手なのかを理解することが必要です。ChatGPTがハルシネーションを起こす可能性がある、学習データに期限があるといった基本的な知識は、すべての医療従事者が持つべきです。

次に、プロンプトエンジニアリングのスキルが求められます。AIに適切な質問をし、求める回答を引き出す技術です。曖昧な質問では曖昧な回答しか得られません。具体的で明確な指示を出すスキルが必要です。

また、批判的思考力も不可欠です。AIの回答を鵜呑みにせず、「本当にこれは正しいか」と常に疑問を持つ姿勢が必要です。特に医療情報では、誤情報が患者の命に関わるため、批判的に情報を評価するスキルが必要です。

情報検索スキルも必要です。AIの回答を確認するため、信頼できる情報源（添付文書、診療ガイドライン、医学データベースなど）で情報を検索するスキルが必要です。PubMedの使い方、UpToDateの活用法など、医療情報源を使いこなすスキルを身につけてください。

データリテラシーも求められます。医療統計、研究デザイン、エビデンスの評価など、データを正しく理解し解釈するスキルです。AIが統計解析を実行してくれても、結果を解釈するのは人間の仕事です。

コミュニケーションスキルはAI時代にこそ必要です。AIは情報を提供できても、患者の不安を理解し、共感し、信頼関係を築くことはできません。患者とのコミュニケーションは、AIには代替できない医療者の価値です。

倫理的判断力も不可欠です。終末期医療、臓器移植、先進医療の選択など、医療には倫理的判断が求められる場面が多くあります。AIは倫理的判断ができないため、人間の倫理観が必要です。

継続学習の姿勢も必要です。AI技術は日々進化し、医療知識も常に更新されます。学び続ける姿勢を持ち、最新の知識とスキルを身につけ続けることが、AI時代の医療従事者には求められます。

### 10.4 プロンプトエンジニアリングの重要性

プロンプトエンジニアリングとは、AIに適切な指示を出して求める回答を引き出す技術です。医療現場でChatGPTを効果的に使うには、このスキルが不可欠です。

良いプロンプトの条件は、まず具体的であることです。「糖尿病について教えてください」という曖昧な質問では、一般論しか返ってきません。「2型糖尿病患者にSGLT2阻害薬を処方する際の注意点を、腎機能、脱水、尿路感染の観点から説明してください」と具体的に指示すれば、実用的な回答が得られます。

次に、出力形式を指定することです。「箇条書きで」「表形式で」「200字以内で」といった形式の指定により、求める形の回答が得やすくなります。忙しい医療現場では、簡潔にまとめられた情報の方が使いやすいでしょう。

役割を与えるのも有効です。「あなたは経験豊富な循環器内科医です。以下の症例について、鑑別診断を挙げてください」といった形で役割を設定すると、より専門的な視点での回答が得られます。

段階的に質問するのも良い方法です。いきなり複雑な質問をするのではなく、まず基本的な情報を確認し、その回答を踏まえて追加の質問をすると、より深い理解が得られます。

具体例を示すことも効果的です。「以下のような形式で診断書のテンプレートを作成してください」と例を示せば、求める形式の文章を生成しやすくなります。

医療特化のプロンプト例をいくつか紹介します。

「心不全治療薬について、作用機序、適応、禁忌、副作用を表形式でまとめてください。」

「以下の英語論文のアブストラクトを日本語で200字以内に要約してください。」

「高齢者向けに、抗凝固薬の服用方法と注意点をわかりやすく説明する資料を作成してください。専門用語は避けて、具体例を含めてください。」

「2群の連続変数を比較する研究で、適切な統計手法を提案してください。データは正規分布に従うと仮定します。」

これらのプロンプトは、具体的な指示、出力形式の指定、対象の明確化といった要素を含んでいます。こうした構造化されたプロンプトを使うことで、ChatGPTからより有用な回答を引き出せます。

プロンプトエンジニアリングのスキルは、練習によって向上します。様々なプロンプトを試し、どのような指示が効果的かを学んでください。医療従事者向けのプロンプト例を集めたウェブサイトや書籍も参考になります。

### 10.5 AIに代替されない医療者の価値

AI技術が進化しても、医療従事者の価値はなくなりません。むしろ、AIには代替できない医療者の価値が、今後より重要になります。

まず、患者との信頼関係はAIには築けません。患者は不安を抱え、悩みを持って医療機関を訪れます。その不安を理解し、共感し、寄り添うことは、人間にしかできません。AIは情報を提供できても、患者の心に寄り添うことはできないです。

次に、全人的医療はAIには実践できません。医療は単なる疾患の治療ではなく、患者の背景、価値観、希望を考慮した全人的なケアが求められます。患者の生活背景を理解し、個別に最適な治療方針を一緒に考えることは、医療者の重要な役割です。

また、臨床判断はAIだけでは不十分です。AIは一般的な医学知識は提供できますが、個々の患者の微妙な症状の変化、身体診察での気づき、経験に基づく直感といった要素は、人間の医療者にしか判断できません。

倫理的判断もAIにはできません。終末期医療の方針、延命治療の選択、限られた医療資源の配分など、医療には倫理的判断が求められる場面が多くあります。これらは人間の価値観と倫理観に基づく判断であり、AIには代替できません。

チーム医療の調整役も人間の役割です。医師、看護師、薬剤師、理学療法士など、多職種が連携する医療現場では、チームをまとめ、コミュニケーションを促進する人間のリーダーシップが不可欠です。

さらに、創造性と柔軟性も人間の強みです。標準的な治療法が効かない場合、新しいアプローチを考えたり、臨床経験から独自の工夫をしたりすることは、人間の創造性が必要です。

AIと共存する時代だからこそ、これらの「人間にしかできないこと」を磨くことが必要です。AIに情報整理や事務作業を任せ、医療者は患者とのコミュニケーション、臨床判断、倫理的配慮といった人間にしかできない価値の高い業務に集中すべきです。

医療従事者の未来は、AIに代替されることではなく、AIを活用して自分の能力を拡張し、より質の高い医療を提供することです。AIは敵ではなく、医療者を支援するパートナーなです。

## まとめ

この記事では、医療現場でのChatGPT活用について、厚生労働省のガイドラインから実践的なプロンプト例、リスク管理、そして未来の展望まで網羅的に解説しました。

まず、ChatGPTは医療現場で完全に禁止されているわけではありません。ただし、2023年5月に策定されたガイドライン第6.0版（Q&Aは2025年5月更新）により、電子カルテ情報の取り扱いには厳格なルールが設けられています。患者の個人情報は絶対に入力してはいけません。完全に匿名化した情報、または個人情報を含まない用途（文献検索、勉強会資料作成など）であれば活用できます。

次に、ChatGPTの活用シーンは多岐にわたります。診断書や紹介状の下書き作成、文献検索と論文要約、患者向け説明資料の作成、医療統計の解析、勉強会資料の準備など、様々な場面で業務効率を向上させられます。実際に、診断書作成時間を10分の1に短縮した医療機関もあります。

ただし、リスクも存在します。個人情報漏洩、ハルシネーション（誤情報）、法的責任、データセキュリティ、偏った情報といったリスクに注意が必要です。特に投与量の誤りや個人情報の入力といった失敗事例から学び、同じミスを繰り返さないようにしてください。

安全に活用するための原則は明確です。個人情報は絶対に入力しない、ChatGPTの回答は必ず確認する、最終判断は必ず人間が行う、この3つの原則を徹底してください。また、医療機関全体で明確なルールを作り、全スタッフに研修を実施することも必要です。

今後、医療AIはさらに進化していくでしょう。精度の向上、医療特化型AIの登場、リアルタイム情報への対応など、多くの発展が期待されます。医療従事者は、AIリテラシー、プロンプトエンジニアリング、批判的思考力といったスキルを身につけ、AIと共存する時代に備える必要があります。

そして忘れてはいけないのは、AIは医療者の仕事を奪うのではなく、支援するパートナーだということです。患者との信頼関係、全人的医療、倫理的判断といった、人間にしかできない価値の高い業務に集中するため、AIを活用してください。

医療現場でのChatGPT活用は、まだ始まったばかりです。正しい知識とスキルを持ち、リスクを理解した上で、安全に活用してください。そうすれば、ChatGPTは医療の質と効率を向上させる強力なツールになります。

## さらに学ぶためのリソース

医療AIやChatGPTについてさらに学びたい方に向けて、有用なリソースを紹介します。

Amazonの読み放題サービス「Kindle Unlimited」では、医療AIやChatGPT関連の書籍も多数読むできます。月額980円で対象書籍が読み放題になるサービスで、無料体験期間もあります。無料で登録できるので、この際に無料で体験できる権利だけでも手に入れておいても損はないと思います。

https://www.amazon.co.jp/kindle-dbs/hz/signup?tag=yakuzaishi.app-22

また、Amazonの「Audible」もおすすめです。通勤中や作業中に医療AIやテクノロジーについて学ぶできます。最近では医療従事者向けのAI活用に関するオーディオブックも増えてきています。

https://www.amazon.co.jp/hz/audible/mlp?tag=yakuzaishi.app-22

これらのサービスを活用すれば、最新の医療AI情報を効率的に学べます。特に通勤時間や休憩時間を使って学習したい方には、Audibleが適しています。

## よくある質問（FAQ）

### Q1: 医療現場でChatGPTは禁止されていますか

完全には禁止されていません。ただし、2023年5月に策定された厚生労働省ガイドライン第6.0版（Q&Aは2025年5月更新）により、電子カルテ情報の取り扱いには厳格なルールが設けられています。患者の個人情報を含まない用途（文献検索、勉強会資料作成など）であれば、活用できます。

### Q2: 患者情報を匿名化すれば入力しても良いですか

完全に匿名化し、個人を特定できる情報がすべて削除されていれば、入力しても個人情報保護の観点からは問題ありません。ただし、氏名、生年月日、住所、カルテ番号など、個人を特定できる情報は絶対に含めないでください。年齢も「70代」のように幅を持たせて表現してください。

### Q3: ChatGPTの診断は信頼できますか

ChatGPTの診断は参考情報として扱うべきで、最終診断には使えません。研究では医師と同程度の診断精度が示されていますが、身体診察ができない、個別の患者背景を考慮できないといった限界があります。診断は必ず医師が行ってください。

### Q4: 投与量の確認にChatGPTを使っても良いですか

推奨しません。ChatGPTは投与量を誤って回答する可能性があります。投与量は必ず添付文書で確認してください。実際に誤った投与量を提示された事例も報告されています。

### Q5: 無料版と有料版の違いは何ですか

無料版は2021年9月までの情報しか持っていません。有料版（ChatGPT Plus）は、Web検索機能で最新情報にアクセスでき、Advanced Data Analysis機能でデータ解析も可能です。ただし、どちらも30日間ログを保存するため、電子カルテ情報の入力は避けるべきです。

### Q6: 医療機関でルールを作る場合、何を含めるべきですか

使用範囲の明確化（何に使って良いか、使ってはいけないか）、個人情報の取り扱いルール、確認手順の義務化、研修の実施、トラブル発生時の対応手順を含めてください。違反した場合の懲戒処分についても明記すべきです。

### Q7: ChatGPT以外のAIツールも使えますか

Gemini（最新情報の検索に強い）、Claude（長文処理に優れる）、HOKUTO（医療特化の臨床支援アプリ）なども活用できます。用途に応じて使い分けてください。ただし、どのツールも個人情報は入力しないという原則は同じです。

### Q8: 医療従事者が身につけるべきスキルは何ですか

AIリテラシー（AIの仕組みと限界の理解）、プロンプトエンジニアリング（適切な質問をするスキル）、批判的思考力（AIの回答を疑う姿勢）、情報検索スキル、データリテラシー、コミュニケーションスキル、倫理的判断力が必要です。

## 参考文献・リソース

### 公式ガイドライン

- 厚生労働省「医療情報システムの安全管理に関するガイドライン第6.0版」（2023年5月策定、Q&Aは2025年5月更新）
- 医療AIプラットフォーム技術研究組合「医療・ヘルスケア分野における生成AI利用ガイドライン第2版」（2024年10月公開）

### 医療情報データベース

- PubMed: 医学論文検索データベース（無料）https://pubmed.ncbi.nlm.nih.gov/
- UpToDate: エビデンスに基づいた臨床情報データベース（有料）
- 今日の臨床サポート: 日本語の臨床情報データベース（有料）

### 医療AI関連ツール

- ChatGPT: https://chat.openai.com/
- Gemini: https://gemini.google.com/
- Claude: https://claude.ai/
- HOKUTO: 医師向け臨床支援アプリ

### 学習リソース

- Kindle Unlimited: 医療AI関連書籍が読み放題 https://www.amazon.co.jp/kindle-dbs/hz/signup?tag=yakuzaishi.app-22
- Audible: オーディオブックで医療AIを学ぶ https://www.amazon.co.jp/hz/audible/mlp?tag=yakuzaishi.app-22

### 関連記事

本ブログの関連記事もご覧ください。

- 「薬剤師のためのChatGPT活用完全ガイド」
- 「医療従事者のための実践的AI活用法」

この記事が、医療現場でのChatGPT活用の一助となれば幸いです。安全に、効果的にAIを活用し、より質の高い医療を提供していきましょう。
